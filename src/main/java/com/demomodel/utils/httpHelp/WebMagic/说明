Selectable  抽取元素
XPath
正则表达式
css选择器


https://proxy.mimvp.com/freesecret  代理服务器地址
爬虫分类
  1、通用网络爬虫
     全网爬虫  互联网上爬取所有数据
  2、聚焦网络爬虫
  慢慢买   爬取有关的数据
  3、增量式网络爬虫
  抓取更新的数据
  4、深层次网络爬虫
              表层网页和深层网页（输入速搜关键词）
 Scheduler是WebMagic中进行 URL 管理的组件。   一般来说，Scheduler包括两个作用：
对待抓取的URL队列进行管理。
对已抓取的URL进行去重      
  DuplicateRemovedScheduler   抽象基类  提供模板方法
  QueueScheduler  使用内存队列保存
  PriorityScheduler  使用带有优先级的内存队列保存抓取的url
  FileCacheQueueScheduler  使用文件保存抓取的url
  RedisScheduler  使用redis保存url
  去重方案       MD5加密 (一个标点改变就认为不一样) bloomFilter (和MD5缺点一样)   推荐使用SimHash
  去重：  hash  bloom(布隆)  Redis
   DuplicateRemover  接口  可以为同一个Scheduler选择不同的去重方式
     hashDuplicateRemover使用hashset来进行去重，占用内存较大   默认
     BloomFilterDuplicateRemover使用布隆过滤器BloomFilter来进行去重，占用内存较小，但是可能露抓页面  
                          可以插入元素，但不可以删除已有元素      其中的元素越多，误报率越大，但是露报是不可能的     使用需要加入guave
                          如果只有一点点不一样，也会认为不重复，这种方式不合理。
     RedisScheduler是使用Redis的set进行去重，其他的scheduler默认都使用hashDuplicateRemover去重
     
     
     
     
   .addHeader("Accept","application/json, text/javascript, */*; q=0.01")
            .addHeader("Accept-Encoding","gzip, deflate, br")
            .addHeader("Accept-Language","zh-CN,zh;q=0.8")
            .addHeader("Connection","keep-alive")
  //content length是指报头以外的内容长度。 一般的服务器实现中，超过这个长度的内容将被抛弃。 不会产生新post。 如果短于内容长度，协议要求服务器返回400错误信息Bad Request(不正确的请求)的。
            //.addHeader("Content-Length","23")//
            .addHeader("Content-Type","application/x-www-form-urlencoded; charset=UTF-8")
 //其实cookie便是模拟登陆的简单实现，也可以通过发送post请求，实现登录。请记住，此处的cookie一定是你登录后浏览这一页的时候的cookie  
            .addHeader("Cookie","Hm_lvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1516684224,1516688332,1516708458,1517989813; _ga=GA1.2.803780703.1515996477; user_trace_token=20180115140756-6e315eee-f9ba-11e7-a353-5254005c3644; LGUID=20180115140756-6e316229-f9ba-11e7-a353-5254005c3644; index_location_city=%E5%85%A8%E5%9B%BD; JSESSIONID=ABAAABAAADEAAFI7B8A950147564B82F61A115D162E1281; LGSID=20180207155015-888d0972-0bdb-11e8-bdd2-525400f775ce; LGRID=20180207163606-f07d2f3d-0be1-11e8-af98-5254005c3644; Hm_lpvt_4233e74dff0ae5bd0a3d81c6ccf756e6=1517992563; TG-TRACK-CODE=index_navigation; SEARCH_ID=ada31aea74d74f0ba5625adf851d1c6f; X_HTTP_TOKEN=4235610f3926fcdc9a4b942f0c350399; _putrc=0DA9DA012C722A8E; login=true; unick=%E7%8E%8B%E5%86%B6; showExpriedIndex=1; showExpriedCompanyHome=1; showExpriedMyPublish=1; hasDeliver=0; gate_login_token=fc49718b5340e22bfe7adebb2937015b765f94906d1f154c; _gat=1")
            .addHeader("Host","www.lagou.com")
            .addHeader("Origin","https://www.lagou.com")
 //这个东西是拉钩网目前为止的反爬机制，其实这个标记，它代表这你访问当前链接的上一个链接，就是你是在A页面点击跳转到B页面，那么B页面的Referer便是A链接
            .addHeader("Referer","https://www.lagou.com/jobs/list_Java")
  //用户代理，这个并不是IP代理，而是一般网站的反爬机制
            .addHeader("User-Agent","-Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3095.5 Mobile Safari/537.36")
            .addHeader("X-Anit-Forge-Code","0")
            .addHeader("X-Anit-Forge-Token","None")
            .addHeader("X-Requested-With","XMLHttpRequest");
————————————————
版权声明：本文为CSDN博主「万无引力 WY」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_36251958/article/details/79313035
     

